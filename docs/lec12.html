<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />




<title>Regression analysis</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/cosmo.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #0000ff; } /* Keyword */
code > span.ch { color: #008080; } /* Char */
code > span.st { color: #008080; } /* String */
code > span.co { color: #008000; } /* Comment */
code > span.ot { color: #ff4000; } /* Other */
code > span.al { color: #ff0000; } /* Alert */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #008000; font-weight: bold; } /* Warning */
code > span.cn { } /* Constant */
code > span.sc { color: #008080; } /* SpecialChar */
code > span.vs { color: #008080; } /* VerbatimString */
code > span.ss { color: #008080; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { } /* Variable */
code > span.cf { color: #0000ff; } /* ControlFlow */
code > span.op { } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #ff4000; } /* Preprocessor */
code > span.do { color: #008000; } /* Documentation */
code > span.an { color: #008000; } /* Annotation */
code > span.cv { color: #008000; } /* CommentVar */
code > span.at { } /* Attribute */
code > span.in { color: #008000; } /* Information */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' || rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>


<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="SI-md-08.css" type="text/css" />

</head>

<body>

<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<div class="container-fluid main-container">

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->





<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Geographic Data Analysis</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="overview.html">Overview</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Topics
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Lecture topics</li>
    <li>
      <a href="lec01.html">Introduction to the course</a>
    </li>
    <li>
      <a href="lec02.html">Univariate plots</a>
    </li>
    <li>
      <a href="lec03.html">Bivariate plots</a>
    </li>
    <li>
      <a href="lec04.html">Descriptive statistics</a>
    </li>
    <li>
      <a href="lec05.html">Multivariate plots</a>
    </li>
    <li>
      <a href="lec06.html">Maps in R</a>
    </li>
    <li>
      <a href="lec07.html">Geospatial analysis in R</a>
    </li>
    <li>
      <a href="lec08.html">Data wrangling and matrix algebra</a>
    </li>
    <li>
      <a href="lec09.html">Reference distributions</a>
    </li>
    <li>
      <a href="lec10.html">Statistical inference</a>
    </li>
    <li>
      <a href="lec11.html">Analysis of variance</a>
    </li>
    <li>
      <a href="lec12.html">Regression analysis</a>
    </li>
    <li>
      <a href="lec13.html">More regression analysis</a>
    </li>
    <li>
      <a href="lec14.html">Nonparametric regression</a>
    </li>
    <li>
      <a href="lec15.html">GLMs, GAMs, and CARTs</a>
    </li>
    <li>
      <a href="lec16.html">Principal components and factor analyses</a>
    </li>
    <li>
      <a href="lec17.html">MANOVA and discriminant analysis</a>
    </li>
    <li>
      <a href="lec18.html">Multivariate distances and cluster analysis</a>
    </li>
    <li>
      <a href="lec19.html">High-resolution and high-dimension data</a>
    </li>
    <li>
      <a href="lec20.html">Analysis and visualization of large raster data sets</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Exercises &amp; Exams
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li class="dropdown-header">Exercises</li>
    <li>
      <a href="ex01.html">Exercise 01 -- Getting R and RStudio</a>
    </li>
    <li>
      <a href="ex02.html">Exercise 02 -- Univariate plots</a>
    </li>
    <li>
      <a href="ex03.html">Exercise 03 -- Bivariate plots and descriptive statistics</a>
    </li>
    <li>
      <a href="ex04.html">Exercise 04 -- Multivariate plots</a>
    </li>
    <li>
      <a href="ex05.html">Exercise 05 -- Data wrangling and matrix algebra</a>
    </li>
    <li>
      <a href="ex06.html">Exercise 06 -- CI's, t-tests, ANOVA</a>
    </li>
    <li>
      <a href="ex07.html">Exercise 07 -- Regression analysis</a>
    </li>
    <li>
      <a href="ex08.html">Exercise 08 -- Multivariate analysis</a>
    </li>
    <li class="dropdown-header">Exams</li>
    <li>
      <a href="exam1_2018.html">Exam 1</a>
    </li>
    <li>
      <a href="exam2_2018.html">Exam 2</a>
    </li>
    <li class="dropdown-header">Other materials</li>
    <li>
      <a href="packages-and-data.html">Packages and Data</a>
    </li>
  </ul>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Resources
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="readings.html">Readings</a>
    </li>
    <li>
      <a href="oldpages.html">Old course web pages</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="about.html">About</a>
</li>
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">Regression analysis</h1>

</div>

<div id="TOC">
<ul>
<li><a href="#introduction"><span class="toc-section-number">1</span> Introduction</a></li>
<li><a href="#regression-basics"><span class="toc-section-number">2</span> Regression basics</a></li>
<li><a href="#example"><span class="toc-section-number">3</span> Example</a><ul>
<li><a href="#fitting-a-regression-equation-or-linear-model"><span class="toc-section-number">3.1</span> Fitting a regression equation (or linear model)</a></li>
<li><a href="#examining-the-regression-equation"><span class="toc-section-number">3.2</span> Examining the regression equation</a></li>
<li><a href="#a-second-example"><span class="toc-section-number">3.3</span> A second example</a></li>
<li><a href="#residual-plots-and-case-wise-statistics"><span class="toc-section-number">3.4</span> Residual plots and case-wise statistics</a></li>
</ul></li>
<li><a href="#iterative-fitting-i.e.brute-force-optimzation-of-a-regression-equation"><span class="toc-section-number">4</span> Iterative fitting (i.e. brute-force optimzation) of a regression equation</a></li>
<li><a href="#examining-the-regression-equation-1"><span class="toc-section-number">5</span> Examining the regression equation</a></li>
<li><a href="#analysis-of-variance"><span class="toc-section-number">6</span> Analysis of Variance</a></li>
<li><a href="#readings"><span class="toc-section-number">7</span> Readings</a></li>
</ul>
</div>

<div id="introduction" class="section level1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<p><em>Regression analysis</em> aims at constructing relationships between a single dependent or response variable and one or more independent or predictor variables, and is one of the more widely used methods in data analysis. Although the computations and analysis that underlie regression analysis appear more complicated than those for other procedures, simple analyses are quite straightforward.</p>
<p>The general model that underlies regression analysis is</p>
<p>        <em>data = predictable component + unpredictable component</em></p>
<p>“Data” in this case are the observed values of the dependent variable, the predictable component consists of the predictions generated by the regression equation, and the unpredictable component consists of the “residuals” or unpredictable parts of the data. The general idea in regression analysis is to move information into the predictable component, leaving the unpredictable component with no information or pattern.</p>
</div>
<div id="regression-basics" class="section level1">
<h1><span class="header-section-number">2</span> Regression basics</h1>
<p>Details of regression analysis, including:</p>
<ul>
<li>the regression model and alternative representations</li>
<li>other quantities in regression analysis (fitted values, residuals, sums of squares)</li>
<li>“fitting” the regression equation</li>
</ul>
<p>can be found <a href="https://pjbartlein.github.io/GeogDataAnalysis/topics/regression1.pdf">here</a>.</p>
<p><a href="lec12.html">[Back to top]</a></p>
</div>
<div id="example" class="section level1">
<h1><span class="header-section-number">3</span> Example</h1>
<p>The simplest regression model is the bivariate one, in which there is one response or dependent variable, and one predictor or independent variable, and the relationship between the two is represented by a straight line.</p>
<div id="fitting-a-regression-equation-or-linear-model" class="section level2">
<h2><span class="header-section-number">3.1</span> Fitting a regression equation (or linear model)</h2>
<p>Building a bivariate linear regression model to represent the relationship between two variables by a straight line involves determining the coefficients of that line, a process known as “fitting” the regression line. First plot the data! <a href="https://pjbartlein.github.io/GeogDataAnalysis/data/csv/regrex1.csv">[regrex1.csv]</a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data=</span>regrex1)</code></pre></div>
<p><img src="lec12_files/figure-html/regr01-1.png" width="2100" /></p>
<p>Fit the model. The <code>lm()</code> (linear model) function creates an object that contains the coefficients of the regression equation, fitted values, residuals, etc. which are saved here in the object <code>ex1_lm</code>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># fit the model</span>
ex1_lm &lt;-<span class="st"> </span><span class="kw">lm</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data=</span>regrex1)</code></pre></div>
<p>Examine the model. “Printing” the object gives a very short summary, while the <code>summary()</code> function produces a a few more details, and the <code>attributes()</code> function reveals what’s contained in the <code>exa1_lm</code> object.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># examine the model object</span>
<span class="kw">print</span>(ex1_lm)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x, data = regrex1)
## 
## Coefficients:
## (Intercept)            x  
##      2.2481       0.4691</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(ex1_lm)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x, data = regrex1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.66121 -0.53286 -0.02869  0.50436  2.36786 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.24814    0.29365   7.656 2.44e-08 ***
## x            0.46906    0.02444  19.194  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.8779 on 28 degrees of freedom
## Multiple R-squared:  0.9294, Adjusted R-squared:  0.9268 
## F-statistic: 368.4 on 1 and 28 DF,  p-value: &lt; 2.2e-16</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">attributes</span>(ex1_lm)</code></pre></div>
<pre><code>## $names
##  [1] &quot;coefficients&quot;  &quot;residuals&quot;     &quot;effects&quot;       &quot;rank&quot;          &quot;fitted.values&quot; &quot;assign&quot;       
##  [7] &quot;qr&quot;            &quot;df.residual&quot;   &quot;xlevels&quot;       &quot;call&quot;          &quot;terms&quot;         &quot;model&quot;        
## 
## $class
## [1] &quot;lm&quot;</code></pre>
<p>The regression line can be visualized by adding it to the existing plot using the <code>abline()</code> function</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># plot the regression line</span>
<span class="kw">plot</span>(y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data=</span>regrex1)
<span class="kw">abline</span>(ex1_lm, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>)</code></pre></div>
<p><img src="lec12_files/figure-html/regr04-1.png" width="2100" /></p>
<p>The individual “deviations” (one per observation) that are being minimized in the analysis can be visualized using the <code>segments()</code> function, which as might be expected plots a line between two points, i.e. between the predicted value of <code>y</code> (retrived using the <code>fitted()</code> function from <code>ex1_lm</code>) and the observed value, at each <code>x</code> value.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span> (y <span class="op">~</span><span class="st"> </span>x, <span class="dt">data=</span>regrex1)
<span class="kw">abline</span>(ex1_lm, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>)
<span class="co"># plot deviations</span>
<span class="kw">segments</span>(regrex1<span class="op">$</span>x, <span class="kw">fitted</span>(ex1_lm), regrex1<span class="op">$</span>x, regrex1<span class="op">$</span>y, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="lec12_files/figure-html/regr05-1.png" width="2100" /></p>
</div>
<div id="examining-the-regression-equation" class="section level2">
<h2><span class="header-section-number">3.2</span> Examining the regression equation</h2>
<p>Once the regression equation has been fit to the data, the next step is to examine the results and the significance of several statistics. First, the standard output</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># examine the model object</span>
ex1_lm</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x, data = regrex1)
## 
## Coefficients:
## (Intercept)            x  
##      2.2481       0.4691</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(ex1_lm)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x, data = regrex1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.66121 -0.53286 -0.02869  0.50436  2.36786 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.24814    0.29365   7.656 2.44e-08 ***
## x            0.46906    0.02444  19.194  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.8779 on 28 degrees of freedom
## Multiple R-squared:  0.9294, Adjusted R-squared:  0.9268 
## F-statistic: 368.4 on 1 and 28 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>The fit of the regression model can also be displayed by plotting confidence intervals (which allow variability in the regression line to be visually assessed) and prediction intervals (which allow variability in the data to be assessed).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># get and plot prediction intervals and confidence intervals</span>
pred_data &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x=</span><span class="kw">seq</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">25</span>))
pred_int &lt;-<span class="st"> </span><span class="kw">predict</span>(ex1_lm, <span class="dt">int=</span><span class="st">&quot;p&quot;</span>, <span class="dt">newdata=</span>pred_data)
conf_int &lt;-<span class="st"> </span><span class="kw">predict</span>(ex1_lm, <span class="dt">int=</span><span class="st">&quot;c&quot;</span>, <span class="dt">newdata=</span>pred_data)
<span class="co"># plot the data</span>
ylim=<span class="kw">range</span>(regrex1<span class="op">$</span>y, pred_int, <span class="dt">na.rm=</span>T, <span class="dt">lwd=</span><span class="dv">2</span>)
<span class="kw">plot</span>(regrex1<span class="op">$</span>x, regrex1<span class="op">$</span>y, <span class="dt">ylim=</span>ylim)
pred_ex1 &lt;-<span class="st"> </span>pred_data<span class="op">$</span>x
<span class="kw">matlines</span>(pred_ex1, pred_int, <span class="dt">lty=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;black&quot;</span>)
<span class="kw">matlines</span>(pred_ex1, conf_int, <span class="dt">lty=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">2</span>), <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)</code></pre></div>
<p><img src="lec12_files/figure-html/regr10-1.png" width="2100" /></p>
</div>
<div id="a-second-example" class="section level2">
<h2><span class="header-section-number">3.3</span> A second example</h2>
<p>Side-by-side comparisons of results of regression analyses provide a means for understanding just what is being described by the summary statistics. A second example shows how the regression equation and goodness-of-fit statistics vary as a function of the strength of the relationship between the response and predictor variable. <a href="https://pjbartlein.github.io/GeogDataAnalysis/data/csv/regrex2.csv">[regrex2.csv]</a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(regrex2)</code></pre></div>
<pre><code>##        e                  x                 y1               y2               y3        
##  Min.   :-1.66120   Min.   : 0.8347   Min.   : 2.281   Min.   : 2.492   Min.   : 2.598  
##  1st Qu.:-0.53280   1st Qu.: 3.6437   1st Qu.: 3.830   1st Qu.: 3.766   1st Qu.: 3.840  
##  Median :-0.02865   Median : 9.8750   Median : 7.006   Median : 6.975   Median : 7.001  
##  Mean   : 0.00001   Mean   :10.0678   Mean   : 6.971   Mean   : 6.970   Mean   : 6.970  
##  3rd Qu.: 0.50430   3rd Qu.:14.4428   3rd Qu.: 9.257   3rd Qu.: 8.935   3rd Qu.: 9.084  
##  Max.   : 2.36790   Max.   :25.0000   Max.   :15.000   Max.   :14.487   Max.   :14.231  
##        y4               y5               y6        
##  Min.   : 2.662   Min.   : 1.154   Min.   :-1.766  
##  1st Qu.: 3.913   1st Qu.: 4.154   1st Qu.: 3.682  
##  Median : 6.928   Median : 7.278   Median : 6.297  
##  Mean   : 6.971   Mean   : 6.971   Mean   : 6.970  
##  3rd Qu.: 9.126   3rd Qu.: 9.036   3rd Qu.: 9.756  
##  Max.   :14.077   Max.   :16.025   Max.   :18.076</code></pre>
<p>The variables x and y1 are the same as in the previous example, so as a second example look at the relationship between y2 and x:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">opar &lt;-<span class="st"> </span><span class="kw">par</span>(<span class="dt">mfcol =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))
<span class="kw">plot</span>(y1 <span class="op">~</span><span class="st"> </span>x, <span class="dt">data=</span>regrex2, <span class="dt">main=</span><span class="st">&quot;Example 1&quot;</span>)
<span class="kw">plot</span>(y2 <span class="op">~</span><span class="st"> </span>x, <span class="dt">data=</span>regrex2, <span class="dt">main=</span><span class="st">&quot;Example 2&quot;</span>)</code></pre></div>
<p><img src="lec12_files/figure-html/regr13-1.png" width="2700" /></p>
<p>Get the second regression:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">ex2_lm &lt;-<span class="st"> </span><span class="kw">lm</span>(y2 <span class="op">~</span><span class="st"> </span>x, <span class="dt">data=</span>regrex2)
<span class="kw">summary</span>(ex2_lm)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y2 ~ x, data = regrex2)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -0.83062 -0.26641 -0.01437  0.25222  1.18393 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.24810    0.14682   15.31  3.9e-15 ***
## x            0.46906    0.01222   38.39  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.439 on 28 degrees of freedom
## Multiple R-squared:  0.9814, Adjusted R-squared:  0.9807 
## F-statistic:  1474 on 1 and 28 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>And compare it with the first:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(ex1_lm)</code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x, data = regrex1)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.66121 -0.53286 -0.02869  0.50436  2.36786 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  2.24814    0.29365   7.656 2.44e-08 ***
## x            0.46906    0.02444  19.194  &lt; 2e-16 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.8779 on 28 degrees of freedom
## Multiple R-squared:  0.9294, Adjusted R-squared:  0.9268 
## F-statistic: 368.4 on 1 and 28 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>Note that the intercept and slope parameter estimates are identical, but all of the measures of goodness-of-fit or of the uncertainty of the parameter values (their standard errors) and significance (t-tests and p-values) are “better” in the second example. Compare the two regression lines and note the differences in the deviations that are being minimized.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">opar &lt;-<span class="st"> </span><span class="kw">par</span>(<span class="dt">mfcol =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>))
<span class="kw">plot</span>(y1 <span class="op">~</span><span class="st"> </span>x, <span class="dt">data=</span>regrex2, <span class="dt">main=</span><span class="st">&quot;Example 1&quot;</span>)
<span class="kw">abline</span>(ex1_lm, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>)
<span class="kw">segments</span>(regrex2<span class="op">$</span>x, <span class="kw">fitted</span>(ex1_lm), regrex2<span class="op">$</span>x, regrex2<span class="op">$</span>y1, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>)
<span class="kw">plot</span>(y2 <span class="op">~</span><span class="st"> </span>x, <span class="dt">data=</span>regrex2, <span class="dt">main=</span><span class="st">&quot;Example 2&quot;</span>)
<span class="kw">abline</span>(ex2_lm, <span class="dt">col=</span><span class="st">&quot;blue&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>)
<span class="kw">segments</span>(regrex2<span class="op">$</span>x, <span class="kw">fitted</span>(ex2_lm), regrex2<span class="op">$</span>x, regrex2<span class="op">$</span>y2, <span class="dt">col=</span><span class="st">&quot;blue&quot;</span>)</code></pre></div>
<p><img src="lec12_files/figure-html/regr16-1.png" width="2700" /></p>
</div>
<div id="residual-plots-and-case-wise-statistics" class="section level2">
<h2><span class="header-section-number">3.4</span> Residual plots and case-wise statistics</h2>
<p>There are a number of residual diagnostic plots that can be generated to examine the regression results as well as to assess the importance of any assumption violations.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># standard regression diagnostics (4-up)</span>
oldpar &lt;-<span class="st"> </span><span class="kw">par</span>(<span class="dt">mfrow =</span> <span class="kw">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))
<span class="kw">plot</span>(ex1_lm, <span class="dt">which=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">5</span>))</code></pre></div>
<p><img src="lec12_files/figure-html/regr11-1.png" width="2700" /></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">par</span>(oldpar)</code></pre></div>
<p>The residual scatterplot (upper left) shows the relationship between the residuals and the fitted values and should show no systematic pattern (“meagaphone” or “arch”) that would signal model inadequecy (i.e., it should be a featureless cloud of points). The red lowess curve helps summarize any trend that might be apparent. The Normal QQ plot (upper right) provides a quick look at the distribution of the residuals, which should be approximately normal (i.e., the individual values should plot along a straight line). Points that plot off the line are labeled with their case numbers (i.e. rows in the data frame). The two plots on the bottom, of Cook’s distance (lower left) and leverage (lower right) provide information on the influence of each observation on the overall regression.</p>
<p><a href="lec12.html">[Back to top]</a></p>
</div>
</div>
<div id="iterative-fitting-i.e.brute-force-optimzation-of-a-regression-equation" class="section level1">
<h1><span class="header-section-number">4</span> Iterative fitting (i.e. brute-force optimzation) of a regression equation</h1>
<p>Regression equations can also be fit by perturbing (or iteratively considering different) regression parameter values, and choosing the combination that minimizes the sum of squares of residuals. The following code sets up a range of potential regression coeffiecient/parameter values that will be interatively considered, keeping track of the sum of squares of deviations for each combination (expressed as the residual standard error for comparison with the the results produced by <code>lm()</code>). (The optimal combination is then the one that minimizes the sum of squares.)</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># fit a linear regression equation by</span>
<span class="co"># minimizing the sum of squared residuals</span>
<span class="co"># uses regrex1.csv</span>

<span class="co"># set some constant values</span>
n &lt;-<span class="st"> </span><span class="kw">length</span>(regrex2<span class="op">$</span>y1)
K &lt;-<span class="st"> </span><span class="dv">1</span>

<span class="co"># intercept values range</span>
n_b0 &lt;-<span class="st"> </span><span class="dv">11</span>
b0_min &lt;-<span class="st"> </span><span class="fl">1.0</span> <span class="co"># 2.00 # 2.24</span>
b0_max &lt;-<span class="st"> </span><span class="fl">3.0</span> <span class="co"># 2.40 # 2.25</span>
<span class="co"># slope values range</span>
n_b1 &lt;-<span class="st"> </span><span class="dv">11</span>
b1_min &lt;-<span class="st"> </span><span class="fl">0.0</span> <span class="co"># 0.4 # 0.46</span>
b1_max &lt;-<span class="st"> </span><span class="fl">1.0</span> <span class="co"># 0.5 # 0.47</span>
<span class="co"># coefficents</span>
b0 &lt;-<span class="st"> </span><span class="kw">seq</span>(b0_min, b0_max, <span class="dt">len=</span>n_b0)
b1 &lt;-<span class="st"> </span><span class="kw">seq</span>(b1_min, b1_max, <span class="dt">len=</span>n_b1)
 
<span class="co"># space for residual standard-error values</span>
rse &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dt">nrow=</span>n_b0<span class="op">*</span>n_b1, <span class="dt">ncol=</span><span class="dv">3</span>)
<span class="kw">colnames</span>(rse) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;b0&quot;</span>, <span class="st">&quot;b1&quot;</span>, <span class="st">&quot;rse&quot;</span>)

<span class="co"># matrix for residual sum of squares</span>
rss &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="ot">NA</span>, <span class="dt">nrow=</span>n_b0, <span class="dt">ncol=</span>n_b1)</code></pre></div>
<p>Now iterate over the combinations of intercept and slope values, keeping track of the residual standard errors and drawing the line produced by each combination.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(y1 <span class="op">~</span><span class="st"> </span>x, <span class="dt">data=</span>regrex2)
m &lt;-<span class="st"> </span><span class="dv">0</span>
<span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n_b0) {
    <span class="cf">for</span> (k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n_b1) {
        m &lt;-<span class="st"> </span>m <span class="op">+</span><span class="st"> </span><span class="dv">1</span>
        sse &lt;-<span class="st"> </span><span class="fl">0.0</span>
        <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {
            sse &lt;-<span class="st"> </span>sse <span class="op">+</span><span class="st"> </span>(regrex2<span class="op">$</span>y1[i] <span class="op">-</span><span class="st"> </span>b0[j] <span class="op">-</span><span class="st"> </span>b1[k]<span class="op">*</span>regrex2<span class="op">$</span>x[i])<span class="op">^</span><span class="dv">2</span>
        }
        rss[j, k] &lt;-<span class="st"> </span>sse
        rse[m,<span class="dv">1</span>] &lt;-<span class="st"> </span>b0[j]
        rse[m,<span class="dv">2</span>] &lt;-<span class="st"> </span>b1[k]
        rse[m,<span class="dv">3</span>] &lt;-<span class="st"> </span><span class="kw">sqrt</span>(sse<span class="op">/</span>(n<span class="op">-</span>K<span class="op">-</span><span class="dv">1</span>))
        <span class="kw">abline</span>(b0[j], b1[k], <span class="dt">col=</span><span class="st">&quot;gray&quot;</span>)
    }
}

<span class="co"># find the coefficients that minimize the rse</span>
m_min &lt;-<span class="st"> </span><span class="kw">which.min</span>(rse[,<span class="dv">3</span>])
<span class="kw">print</span>(m_min)</code></pre></div>
<pre><code>## [1] 61</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>(<span class="kw">c</span>(rse[m_min,<span class="dv">1</span>],rse[m_min,<span class="dv">2</span>],rse[m_min,<span class="dv">3</span>]))</code></pre></div>
<pre><code>##        b0        b1       rse 
## 2.0000000 0.5000000 0.9050813</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># plot the line for the optimal coefficients</span>
<span class="kw">abline</span>(rse[m_min,<span class="dv">1</span>],rse[m_min,<span class="dv">2</span>], <span class="dt">col=</span><span class="st">&quot;purple&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>)
<span class="co"># plot the OLS regression line</span>
<span class="kw">abline</span>(ex1_lm, <span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>)</code></pre></div>
<p><img src="lec12_files/figure-html/regr08-1.png" width="2100" /></p>
<p>The <code>which.min()</code> function determines the row in the <code>rse</code> matrix of the minimum (i.e. “optimal”) residual standard error, and the corresponding parameter values are then printed out. The regression line generated by those values is plotted in blue, and can be compared with the OLS estimates in red. Pretty close.</p>
<p>It’s useful to see the residual-sum-of-squares surface, which shows graphically how the goodness-of-fit varies as the regression coefficient values change.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">image</span>(b0, b1, rss, <span class="dt">col  =</span> <span class="kw">gray</span>((<span class="dv">0</span><span class="op">:</span><span class="dv">64</span>)<span class="op">/</span><span class="dv">64</span>))</code></pre></div>
<p><img src="lec12_files/figure-html/rss%20surface-1.png" width="2100" /></p>
<p>The values in the <code>rss</code> matrix can be inspected using the <code>View()</code> function.</p>
<p><a href="lec12.html">[Back to top]</a></p>
</div>
<div id="examining-the-regression-equation-1" class="section level1">
<h1><span class="header-section-number">5</span> Examining the regression equation</h1>
<p>Examination of the regression equation involves an assessment of the “strength” of the relationship between the response variable and the predictor variable(s). Two hypothesis tests are considered:</p>
<ul>
<li>a test of the null hypothesis that the proportion of the variance of the response variable “explained” by the predictor variable(s) is not significant (an <em>F</em>-test, analogous to the one in ANOVA of the hypothesis that the group means are not different)</li>
<li>individual tests of the null hypotheses that the estimated regression coefficients (<em>b<sub>0</sub></em>, <em>b<sub>1</sub></em>) are equal to zero.</li>
</ul>
<p>The two hypotheses are tested by examining the regression equation and related statistics</p>
<ul>
<li>decomposition of individual deviations</li>
<li>how strong is the relationship? (<em>F</em>-test, <em>R<sup>2</sup></em>)</li>
<li>are the coefficients significant? (<em>t</em>-tests and standard errors of the predictions)</li>
</ul>
<p>The fit of the regression model can also be displayed by plotting confidence intervals (which allow variability in the regression line to be visually assessed) and prediction intervals (which allow variability in the data to be assessed).</p>
<p><a href="lec12.html">[Back to top]</a></p>
</div>
<div id="analysis-of-variance" class="section level1">
<h1><span class="header-section-number">6</span> Analysis of Variance</h1>
<p>One of the main elements of the output in fitting a regression equation is the <em>analysis of variance table</em>, which as sounds, has some parallels with “Analysis of Variance” (ANOVA) the procedure for testing for equality of group means. In regression analysis, the decomposition of the variance of the dependent variable is</p>
<p>        <em>variance of response = variance “explained” by regression + residual variance (noise)</em></p>
<p>In ANOVA, the total variance of the variable of interest is decomposed as</p>
<p>        <em>total variance = between-group variance + within-group variance</em></p>
<p>If ANOVA is thought of as evaluating how much of the variability of a “response” variable can be explained by knowing which group each observation belongs to, then the similarity of the analyses can be seen.</p>
<p><a href="lec12.html">[Back to top]</a></p>
</div>
<div id="readings" class="section level1">
<h1><span class="header-section-number">7</span> Readings</h1>
<ul>
<li>Kuhnert &amp; Venebles (<em>An Introduction…</em>): p. 109-120;<br />
</li>
<li>Maindonald (<em>Using R…</em>): ch. 5</li>
</ul>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
